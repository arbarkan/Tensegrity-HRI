{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trying\n",
    "\n",
    "Research Diary: https://drive.google.com/open?id=1zBXLaCameGhHj8RbXeGkep6_gZnUAiAnhGrVE1aEr-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from copy import deepcopy\n",
    "import math\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force divider function\n",
    "def force_divider(x):\n",
    "    k_outer = 3.738\n",
    "    k_inner = 0.368\n",
    "    dist = x/k_inner\n",
    "    return (k_outer + k_inner)*dist\n",
    "\n",
    "# FSR model function\n",
    "def FSR_model(x):\n",
    "    return 131.2*np.exp(0.7801*x)/1000\n",
    "\n",
    "# Total impulse function for a single matrix of data \n",
    "# Iterates over data and computes the total impulse for all sensors over time\n",
    "def impulse(data_matrix): \n",
    "    fsr_data = data_matrix\n",
    "    impulse = 0\n",
    "    for col in range(0, 12):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        for i in range(0, 1000):\n",
    "            averagef = (single_FSR[i+1] + single_FSR[i])/2 \n",
    "            impulse = impulse + averagef\n",
    "    return impulse \n",
    "\n",
    "# Return a numpy array containing the differential between consecutive elements (approximation of slope) \n",
    "# in a given data array\n",
    "def slope(dataVector):\n",
    "    dydx = []\n",
    "    for i in range(1, len(dataVector)):\n",
    "        diff = dataVector[i] - dataVector[i-1]\n",
    "        dydx.append(diff)\n",
    "    finalDiff = dataVector[i] - dataVector[i-1] # Added just to make the final array the proper dimensions \n",
    "    dydx.append(finalDiff)\n",
    "    return np.array(dydx)\n",
    "\n",
    "# Return a numpy array containing the value and index of the largest magnitude value in given data array (first instance)\n",
    "def largest(dataVector):\n",
    "    val = max(abs(dataVector))\n",
    "    ind = 0\n",
    "    for k in dataVector:\n",
    "        if abs(k) == val:\n",
    "            return np.array([val, ind])\n",
    "        else:\n",
    "            ind += 1\n",
    "\n",
    "# Mean function\n",
    "def mean(dataVec):\n",
    "    return sum(dataVec) / len(dataVec)\n",
    "\n",
    "# Standard Deviation\n",
    "def sd(dataVec):\n",
    "    avg = mean(dataVec)\n",
    "    tot = 0\n",
    "    for elem in dataVec:\n",
    "        tot = tot + (elem - avg)*(elem - avg)\n",
    "    return math.sqrt(tot / len(dataVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "    # Fall = 1\n",
    "    # Impact = 2\n",
    "    # Nothing = 3\n",
    "    # Squeeze = 4\n",
    "    \n",
    "# Add Fall data\n",
    "string = \"/Users/alber/Desktop/BEST/Tensegrity-HRI/DataV2/fall\"\n",
    "numbers = np.arange(1,15)\n",
    "fsrData = []\n",
    "accelData = []\n",
    "totData = []\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    fsrFall = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\"]]\n",
    "    accelFall = d[[\"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    totFall = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    fsrFall = fsrFall.to_numpy()\n",
    "    accelFall = accelFall.to_numpy()\n",
    "    totFall = totFall.to_numpy()\n",
    "    fsrData.append(fsrFall)\n",
    "    accelData.append(accelFall)\n",
    "    totData.append(totFall)\n",
    "\n",
    "    \n",
    "# Add Impact data\n",
    "string = \"/Users/alber/Desktop/BEST/Tensegrity-HRI/DataV2/impact\"\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    fsrImp = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                \"FSR_12\"]]\n",
    "    accelImp = d[[\"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    totImp = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    fsrImp = fsrImp.to_numpy()\n",
    "    accelImp = accelImp.to_numpy()\n",
    "    totImp = totImp.to_numpy()\n",
    "    fsrData.append(fsrImp)\n",
    "    accelData.append(accelImp)\n",
    "    totData.append(totImp)\n",
    "\n",
    "    \n",
    "# Add Nothing data\n",
    "string = \"/Users/alber/Desktop/BEST/Tensegrity-HRI/DataV2/nothing\"\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    fsrNoth = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\"]]\n",
    "    accelNoth = d[[\"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    totNoth = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    fsrNoth = fsrNoth.to_numpy()\n",
    "    accelNoth = accelNoth.to_numpy()\n",
    "    totNoth = totNoth.to_numpy()\n",
    "    fsrData.append(fsrNoth)\n",
    "    accelData.append(accelNoth)\n",
    "    totData.append(totNoth)\n",
    "    \n",
    "# Add Squeeze data\n",
    "string = \"/Users/alber/Desktop/BEST/Tensegrity-HRI/DataV2/squeeze\"\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    fsrSqueeze = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\"]]\n",
    "    accelSqueeze = d[[\"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    totSqueeze = d[[\"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \n",
    "                 \"FSR_12\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    fsrSqueeze = fsrSqueeze.to_numpy()\n",
    "    accelSqueeze = accelSqueeze.to_numpy()\n",
    "    totSqueeze = totSqueeze.to_numpy()\n",
    "    fsrData.append(fsrSqueeze)\n",
    "    accelData.append(accelSqueeze)\n",
    "    totData.append(totSqueeze)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fsr data to Newtons\n",
    "placeHold = []\n",
    "for m in fsrData:\n",
    "    m = force_divider(FSR_model(m *5/1023))  \n",
    "    placeHold.append(m)\n",
    "\n",
    "for k in totData:\n",
    "    k[:, 0:12] = force_divider(FSR_model(k[:, 0:12] *5/1023))\n",
    "\n",
    "fsrData = placeHold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FSR data (Taking first tests as example)\n",
    "# plt.figure(figsize=(20, 15))\n",
    "# plt.subplot(221)\n",
    "# plt.plot(fsrData[0])\n",
    "# plt.subplot(222)\n",
    "# plt.plot(fsrData[14])\n",
    "# plt.subplot(223)\n",
    "# plt.plot(fsrData[28])\n",
    "# plt.subplot(224)\n",
    "# plt.plot(fsrData[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accel data\n",
    "# plt.figure(figsize=(20, 15))\n",
    "# plt.subplot(221)\n",
    "# plt.plot(accelData[0])\n",
    "# plt.subplot(222)\n",
    "# plt.plot(accelData[14])\n",
    "# plt.subplot(223)\n",
    "# plt.plot(accelData[28])\n",
    "# plt.subplot(224)\n",
    "# plt.plot(accelData[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try smoothing out fsr data\n",
    "\n",
    "fsrRefined = deepcopy(fsrData)\n",
    "\n",
    "for test in fsrRefined:\n",
    "    for k in range(0, 12):\n",
    "        test[:, k] = signal.savgol_filter(test[:, k], 71, 3)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try smoothing out acceleration data\n",
    "accelRefined = deepcopy(accelData)\n",
    "\n",
    "for test in accelRefined:\n",
    "    for k in range(0, 3):\n",
    "        test[:, k] = signal.savgol_filter(test[:, k], 71, 3)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try smoothing out total Data\n",
    "totRefined = deepcopy(totData)\n",
    "\n",
    "for test in totRefined:\n",
    "    for k in range(0, 15):\n",
    "        test[:, k] = signal.savgol_filter(test[:, k], 71, 3)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at acceleration data of four types of tests\n",
    "# plt.figure(figsize=(20,15))\n",
    "# plt.subplot(221)\n",
    "# for i in range(0, 3):\n",
    "#     plt.plot(accelRefined[0][:, i])\n",
    "# plt.subplot(222)\n",
    "# for i in range(0, 3):\n",
    "#     plt.plot(accelRefined[14][:, i])  \n",
    "# plt.subplot(223)\n",
    "# for i in range(0, 3):\n",
    "#     plt.plot(accelRefined[28][:, i])  \n",
    "# plt.subplot(224)\n",
    "# for i in range(0, 3):\n",
    "#     plt.plot(accelRefined[42][:, i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 1001, 12)\n",
      "(56, 1001, 12)\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "# Generate slope vectors for accel data, plot\n",
    "accelSlopes = []\n",
    "for i in range(0, 56):\n",
    "    accelVec = slope(accelRefined[i])\n",
    "    accelSlopes.append(accelVec)\n",
    "\n",
    "# Slope vectors for FSR data\n",
    "fsrSlopes = []\n",
    "for i in range(0, 56):\n",
    "    fsrVec = slope(fsrRefined[i])\n",
    "    fsrSlopes.append(fsrVec)\n",
    "\n",
    "print(np.shape(fsrRefined))\n",
    "print(np.shape(fsrSlopes))\n",
    "print(len(fsrRefined[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean acceleration slope data\n",
    "slopeRefined = deepcopy(accelSlopes)\n",
    "\n",
    "for test in slopeRefined:\n",
    "    for k in range(0, 3):\n",
    "        test[:, k] = signal.savgol_filter(test[:, k], 71, 3)  \n",
    "\n",
    "# Clean FSR slope data\n",
    "fsrSlopeRef = deepcopy(fsrSlopes)\n",
    "for test in fsrSlopeRef:\n",
    "    for k in range(0, 12):\n",
    "        test[:, k] = signal.savgol_filter(test[:, k], 71, 3)  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 1001, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create combinations of data arrays\n",
    "# Arrays that matter: fsrRefined, accelRefined, slopeRefined, totRefined, fsrSlopeRef\n",
    "\n",
    "# Total data + accelerometer slopes\n",
    "totSlope = []\n",
    "for i in range(0, 56):\n",
    "    combinedData = np.append(totRefined[i], slopeRefined[i], axis = 1)\n",
    "    totSlope.append(combinedData)\n",
    "\n",
    "# FSR data + accelerometer slopes\n",
    "fsrSlope = []\n",
    "for i in range(0, 56):\n",
    "    combinedData = np.append(fsrRefined[i], slopeRefined[i], axis = 1)\n",
    "    fsrSlope.append(combinedData)\n",
    "\n",
    "# Accelerometer data + accelerometer slopes\n",
    "accelAndSlope = []\n",
    "for i in range(0, 56):\n",
    "    combinedData = np.append(accelRefined[i], slopeRefined[i], axis = 1)\n",
    "    accelAndSlope.append(combinedData)\n",
    "\n",
    "# FSR data + fsr slopes\n",
    "fsrAndSlope = []\n",
    "for i in range(0, 56):\n",
    "    combinedData = np.append(fsrRefined[i], fsrSlopeRef[i], axis = 1)\n",
    "    fsrAndSlope.append(combinedData)\n",
    "\n",
    "print(np.shape(fsrAndSlope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize mean and standard deviation\n",
    "\n",
    "# print(\"Original Means:\")\n",
    "# for col in range(0, 24):\n",
    "#     print(mean(fsrAndSlope[0][:, col]))\n",
    "# print(\"\\n\")\n",
    "# print(\"Original SDs:\")\n",
    "# for col in range(0, 24):\n",
    "#     print(sd(fsrAndSlope[0][:, col]))\n",
    "\n",
    "\n",
    "# for test in fsrAndSlope:\n",
    "#     for k in range(0, 24):\n",
    "#         test[:, k] = test[:, k] - mean(test[:, k])\n",
    "#         test[:, k] = test[:, k] / sd(test[:, k])\n",
    "\n",
    "# print(\"New Means:\")\n",
    "# for col in range(0, 24):\n",
    "#     print(mean(fsrAndSlope[0][:, col]))\n",
    "# print(\"\\n\")\n",
    "# print(\"New SDs:\")\n",
    "# for col in range(0, 24):\n",
    "#     print(sd(fsrAndSlope[0][:, col]))\n",
    "\n",
    "# plt.figure(figsize=(15, 20))\n",
    "# plt.subplot(311)\n",
    "# plt.plot(fsrAndSlope[0])\n",
    "# plt.subplot(312)\n",
    "# plt.plot(fsrAndSlope[20])\n",
    "# plt.subplot(313)\n",
    "# plt.plot(fsrAndSlope[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels!\n",
    "\n",
    "l1 = np.ones((14,), dtype=int) \n",
    "l2 = 2*np.ones((14,), dtype=int) \n",
    "l3 = 3*np.ones((14,), dtype=int)\n",
    "l4 = 4*np.ones((14,), dtype=int)\n",
    "labels = np.concatenate((l1, l2, l3, l4), axis=0)\n",
    "\n",
    "\n",
    "# Prepare data for algorithms\n",
    "nsamples, nx, ny = np.shape(fsrSlope)\n",
    "reformated_data = np.reshape(fsrSlope,(nsamples, nx*ny))\n",
    "[X_train, X_test, y_train, y_test] = train_test_split(reformated_data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "X = reformated_data\n",
    "y = labels\n",
    "skf = StratifiedKFold(n_splits=4)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6875\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive-Bayes\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    nb = GaussianNB().fit(X_train, y_train)\n",
    "    print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n",
      "0.6875\n",
      "0.5833333333333334\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    nb = RandomForestClassifier().fit(X_train, y_train)\n",
    "    print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try PCA on accelerometer data\n",
    "\n",
    "pcaAccel = deepcopy(fsrSlope)\n",
    "pca = PCA(n_components = 1)\n",
    "\n",
    "for i in range(0, 56):\n",
    "    pcaAccel[i] = pca.fit_transform(pcaAccel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on FSR data\n",
    "pcaFSR = deepcopy(fsrAndSlope)\n",
    "pca2 = PCA(n_components = 1)\n",
    "\n",
    "for i in range(0, 56):\n",
    "    pcaFSR[i] = pca2.fit_transform(pcaFSR[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.9375\n",
      "0.75\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Run script on data\n",
    "\n",
    "# Prepare data for algorithms\n",
    "nsamples2, nx2, ny2 = np.shape(pcaFSR)\n",
    "reformated_data2 = np.reshape(pcaFSR,(nsamples2, nx2*ny2))\n",
    "[X_train2, X_test2, y_train2, y_test2] = train_test_split(reformated_data2, labels, random_state=0)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "X2 = reformated_data2\n",
    "y2 = labels\n",
    "skf2 = StratifiedKFold(n_splits=4)\n",
    "skf2.get_n_splits(X2, y2)\n",
    "\n",
    "# Gaussian Naive-Bayes\n",
    "for train_index, test_index in skf2.split(X2, y2):\n",
    "    X_train, X_test, y_train, y_test = X2[train_index], X2[test_index], y2[train_index], y2[test_index]\n",
    "    nb = GaussianNB().fit(X_train, y_train)\n",
    "    print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n",
      "0.9375\n",
      "0.9166666666666666\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "for train_index, test_index in skf2.split(X2, y2):\n",
    "    X_train, X_test, y_train, y_test = X2[train_index], X2[test_index], y2[train_index], y2[test_index]\n",
    "    nb = RandomForestClassifier().fit(X_train, y_train)\n",
    "    print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
