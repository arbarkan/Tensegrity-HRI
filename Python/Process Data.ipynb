{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import random\n",
    "from scipy import signal\n",
    "from copy import copy, deepcopy\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Force Divider Function\n",
    "def force_divider(x):\n",
    "    k_outer = 3.738\n",
    "    k_inner = 0.368\n",
    "    dist = x/k_inner\n",
    "    return (k_outer + k_inner)*dist\n",
    "\n",
    "#FSR model function\n",
    "def FSR_model(x):\n",
    "    return 131.2*np.exp(0.7801*x)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Old Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old dataset has three kinds of data: Drop, Squeeze and Nothing. After running this cell below, it is loaded into the variable named dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 7001, 16)\n"
     ]
    }
   ],
   "source": [
    "#thank you Sala for your 7 second cropped data \n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\old_data\\test'\n",
    "dataset = []\n",
    "file_numbers = np.arange(1,73) \n",
    "\n",
    "for num in file_numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    d = d.drop(columns = [\"IND\"])\n",
    "    d = d.to_numpy()\n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "\n",
    "    #interpolation for even time steps \n",
    "    length = np.shape(d)[0] \n",
    "    new_t = np.linspace(d[0,0],d[length-1,0],length,endpoint = True)\n",
    "    for col in np.arange(1,16):\n",
    "        single_FSR = d[:,col]\n",
    "        time = d[:,0]\n",
    "        function = interp1d(time, single_FSR)\n",
    "        new_data = function(new_t)\n",
    "        d[:,col] = new_data \n",
    "    d[:,0] = new_t\n",
    "#     print(np.shape(d[0]))\n",
    "    dataset.append(d)\n",
    "    \n",
    "print(np.shape(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new datat sets consists of Drop , Squeeze , Handle, Roll and Nothing Data. Running the cell below loads it into the respective variables newDrop, newHandle , newRoll, newSqueeze , newNothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "    # Drop = 1 (starts at ind 0)\n",
    "    # Handle = 2 (starts at ind 21)\n",
    "    # Roll = 3 (starts at ind 73)\n",
    "    # Squeeze = 4 (starts at ind 88)\n",
    "    # Nothing = 5 (starts at ind 178)\n",
    "\n",
    "newDrop = []\n",
    "newHandle = []\n",
    "newRoll = []\n",
    "newSqueeze = []\n",
    "newNothing = []\n",
    "\n",
    "    \n",
    "# Add Drop data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Drop\\drop'\n",
    "numbers = np.arange(1,21)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    \n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    d = d.drop(columns = [\"IND\"])\n",
    "    d = d.to_numpy()\n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newDrop.append(d)\n",
    "    \n",
    "# Add Handle data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Handle\\handleTest'\n",
    "numbers = np.arange(1, 53)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"Nothing\", \"IND\", \"time\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\", \n",
    "                                       \"QUAT_Z\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\"])\n",
    "    \n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"Nothing\", \"IND\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\",\"QUAT_Z\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newHandle.append(d)\n",
    "\n",
    "# Add Roll data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Roll\\rollTest'\n",
    "numbers = np.arange(1, 15)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"Nothing\", \"IND\", \"time\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\", \n",
    "                                       \"QUAT_Z\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\"])\n",
    "   \n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"Nothing\", \"IND\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\",\"QUAT_Z\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newRoll.append(d)\n",
    "\n",
    "\n",
    "    \n",
    "# Add Squeeze data\n",
    "\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Squeeze\\squeeze'\n",
    "numbers = np.arange(56, 90)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    \n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"IND\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newSqueeze.append(d)\n",
    "    \n",
    "\n",
    "    \n",
    "# Add More Squeeze data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Squeeze\\squeeze'\n",
    "numbers = np.arange(1, 56)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"Nothing\", \"IND\", \"time\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\", \n",
    "                                       \"QUAT_Z\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\"])\n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"Nothing\", \"IND\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\",\"QUAT_Z\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newSqueeze.append(d)\n",
    "    \n",
    "    \n",
    "# Add Nothing data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Nothing\\nothing'\n",
    "numbers = np.arange(48, 57)\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "                                              \"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"IND\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newNothing.append(d)\n",
    "    \n",
    "\n",
    "# Add More Nothing data\n",
    "string = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\new_data\\Nothing\\nothing'\n",
    "\n",
    "numbers = np.arange(2, 48)\n",
    "\n",
    "for num in numbers:\n",
    "    filename = string + str(num) + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"Nothing\", \"IND\", \"time\", \"ACC_X\", \"ACC_Y\", \"ACC_Z\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\", \n",
    "                                       \"QUAT_Z\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "                                               \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\"])\n",
    "    \n",
    "    d[\"time\"] = d[\"time\"].apply(lambda x: (x - d[\"time\"][0])*1e-6)   #convert time to seconds\n",
    "    \n",
    "    d = d.drop(columns = [\"Nothing\", \"IND\", \"QUAT_W\", \"QUAT_X\", \"QUAT_Y\",\"QUAT_Z\"])\n",
    "    \n",
    "    d = d[[\"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \n",
    "            \"FSR_6\", \"FSR_7\", \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\n",
    "            \"ACC_X\", \"ACC_Y\", \"ACC_Z\"]]\n",
    "    \n",
    "    d = d.to_numpy()\n",
    "    \n",
    "    d[:,1:13] = force_divider(FSR_model(d[:,1:13] *5/1023)) #convert force from raw data to newtons\n",
    "    \n",
    "    newNothing.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "52\n",
      "14\n",
      "89\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(newDrop))\n",
    "print(len(newHandle))\n",
    "print(len(newRoll))\n",
    "print(len(newSqueeze))\n",
    "print(len(newNothing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell specificies indices for the 72 sets in the old dataset. The first set of indices is the nothing data, then is drop data and lastly squeeze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "indices_dict[1] = [[], [], []]\n",
    "indices_dict[2] = [[], [], []]\n",
    "indices_dict[3] = [[], [], []]\n",
    "indices_dict[4] = [[[0, 750], [2301, 2750], [4101, 4550], [6201, 7001]], [], [[751, 2300], [2751, 4100], [4551, 6200]]]\n",
    "indices_dict[5] = [[[0, 900], [1501, 3300], [3901, 5700], [6301, 7001]], [], [[901, 1500], [3301, 3900], [5701, 6300]]]\n",
    "indices_dict[6] = [[[0, 1100], [1751, 2750], [3401, 4400], [5101, 7001]], [], [[1101, 1750], [2751, 3400], [4401, 5100]]]\n",
    "indices_dict[7] = [[[0, 1700], [2501, 3000], [3651, 4250], [5051, 7001]], [], [[1701, 2500], [3001, 3650], [4251, 5050]]]\n",
    "indices_dict[8] = [[[0, 1500], [2151, 2650], [3326, 3850], [4551, 7001]], [], [[1501, 2150], [2651, 3325], [3851, 4550]]]\n",
    "indices_dict[9] = [[[0, 2200], [2851, 3450], [4151, 4600], [5301, 7001]], [], [[2201, 2850], [3451, 4150], [4601, 5300]]]\n",
    "indices_dict[10] = [[], [], []]\n",
    "indices_dict[11] = [[], [], []]\n",
    "indices_dict[12] = [[[0, 1000], [2501, 3000], [4251, 5000], [6301, 7001]], [], [[1001, 2500], [3001, 4250], [5001, 6300]]]\n",
    "indices_dict[13] = [[], [], []] #todo\n",
    "indices_dict[14] = [[], [], []] #todo\n",
    "indices_dict[15] = [[], [], []] #todo\n",
    "indices_dict[16] = [[], [], []] #todo\n",
    "indices_dict[17] = [[], [], []] #todo\n",
    "indices_dict[18] = [[[0, 2100], [3801, 7001]], [[2101, 3800]], []]\n",
    "indices_dict[19] = [[[0, 1700], [3101, 7001]], [[1701, 3100]], []]\n",
    "indices_dict[20] = [[], [], []] #this data seems messed up \n",
    "indices_dict[21] = [[], [], []] #this data seems messed up \n",
    "indices_dict[22] = [[[0, 2600], [4051, 7001]], [[2601, 4050]], []]\n",
    "indices_dict[23] = [[[0, 1850], [3651, 7001]], [[1851, 3650]], []]\n",
    "indices_dict[24] = [[[0, 2250], [4501, 7001]], [[2251, 4500]], []]\n",
    "indices_dict[25] = [[[0, 2500], [4051, 7001]], [[2501, 4050]], []]\n",
    "indices_dict[26] = [[], [], []] #node\n",
    "indices_dict[27] = [[[0, 2850], [4601, 7001]], [[2851, 4600]], []]\n",
    "indices_dict[28] = [[[0, 3000], [4601, 7001]], [[3001, 4600]], []]\n",
    "indices_dict[29] = [[[0, 1500], [3251, 7001]], [[1501, 3250]], []]\n",
    "indices_dict[30] = [[[0, 1900], [3001, 7001]], [[1901, 3000]], []]\n",
    "indices_dict[31] = [[[0, 1950], [3701, 7001]], [[1951, 3700]], []]\n",
    "indices_dict[32] = [[[0, 2650], [4251, 7001]], [[2651, 4250]], []]\n",
    "indices_dict[33] = [[], [], []] #sensor failures\n",
    "indices_dict[34] = [[], [], []] #sensor failures\n",
    "indices_dict[35] = [[[0, 2000], [4801, 7001]], [], [[2001, 4800]]]\n",
    "indices_dict[36] = [[[0, 2000], [5501, 7001]], [], [[2001, 5500]]]\n",
    "indices_dict[37] = [[], [], []] #node\n",
    "indices_dict[38] = [[[0, 7701]], [], []] #only nothing data\n",
    "indices_dict[39] = [[[0, 1100], [2301, 2500], [3801, 4050], [5301, 7001]], [], [[1101, 2300], [2501, 3800], [4051, 5300]]]\n",
    "indices_dict[40] = [[], [], []] #sensor failures\n",
    "indices_dict[41] = [[], [], []] #sensor failures\n",
    "indices_dict[42] = [[], [], []] #sensor failures\n",
    "indices_dict[43] = [[], [], []] #sensor failures\n",
    "indices_dict[44] = [[], [], []] #sensor failures\n",
    "indices_dict[45] = [[], [], []] #sensor failures\n",
    "indices_dict[46] = [[], [], []] #sensor failures\n",
    "indices_dict[47] = [[[0, 2000], [2901, 3250], [4251, 4500], [5501, 7001]], [], [[2001, 2900], [3251, 4250], [4501, 5500]]]\n",
    "indices_dict[48] = [[[0, 1800], [2751, 3250], [4001, 4500], [5251, 7001]], [], [[1801, 2750], [3251, 4000], [4501, 5250]]]\n",
    "indices_dict[49] = [[], [], []] #sensor failures\n",
    "indices_dict[50] = [[[0, 1800], [2601, 3000], [3851, 4200], [5101, 7001]], [], [[1801, 2600], [3001, 3850], [4201, 5100]]]\n",
    "indices_dict[51] = [[], [], []] #todo\n",
    "indices_dict[52] = [[], [], []] #todo\n",
    "indices_dict[53] = [[], [], []] #todo\n",
    "indices_dict[54] = [[], [], []] #todo\n",
    "indices_dict[55] = [[], [], []] #todo\n",
    "indices_dict[56] = [[], [], []] #todo\n",
    "indices_dict[57] = [[], [], []] #todo\n",
    "indices_dict[58] = [[], [], []] #todo\n",
    "indices_dict[59] = [[], [], []] #todo\n",
    "indices_dict[60] = [[], [], []] #todo\n",
    "indices_dict[61] = [[], [], []] #todo\n",
    "indices_dict[62] = [[], [], []] #todo\n",
    "indices_dict[63] = [[], [], []] #todo\n",
    "indices_dict[64] = [[], [], []] #todo\n",
    "indices_dict[65] = [[], [], []] #todo\n",
    "indices_dict[66] = [[], [], []] #todo\n",
    "indices_dict[67] = [[], [], []] #todo\n",
    "indices_dict[68] = [[], [], []] #todo\n",
    "indices_dict[69] = [[], [], []] #todo\n",
    "indices_dict[70] = [[], [], []] #todo\n",
    "indices_dict[71] = [[], [], []] #todo\n",
    "indices_dict[72] = [[], [], []] #todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below creates a datset given a certian window size. It slides over the datapoint and creates samples according to the window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(window_size):\n",
    "    nothing = []\n",
    "    drop = []\n",
    "    squeeze = []\n",
    "    handle = []\n",
    "    roll = []\n",
    "    \n",
    "    \n",
    "    print('Window Size= ' + str(window_size))\n",
    "    for n in np.arange(1,72):\n",
    "        indices = indices_dict[n]\n",
    "        data = dataset[n]\n",
    "        for l in indices[0]: #cropping for nothing data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[1]: #cropping for drop data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[2]: #cropping for squeeze data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    for sample in newNothing:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newHandle:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                handle.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newDrop:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newSqueeze:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newRoll:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                roll.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    final_data = nothing+drop+squeeze+handle+roll\n",
    "    \n",
    "    #create labels \n",
    "    #nothing = 1\n",
    "    #drop = 2\n",
    "    #squeeze = 3\n",
    "    nothing_labels = [1] * len(nothing)\n",
    "    print('Number of nothing data: ' + str(len(nothing_labels)))\n",
    "    drop_labels = [2] * len(drop)\n",
    "    print('Number of drop data: ' + str(len(drop_labels)))\n",
    "    squeeze_labels = [3] * len(squeeze)\n",
    "    print('Number of squeeze data: ' + str(len(squeeze_labels)))\n",
    "    \n",
    "    handle_labels = [4] * len(handle)\n",
    "    print('Number of Handle data: ' + str(len(handle_labels)))\n",
    "    \n",
    "    roll_labels = [5] * len(roll)\n",
    "    print('Number of Roll data: ' + str(len(roll_labels)))\n",
    "    \n",
    "    labels = nothing_labels + drop_labels + squeeze_labels + handle_labels + roll_labels\n",
    "    \n",
    "    print(np.shape(labels))\n",
    "    return final_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_noroll(window_size):\n",
    "    nothing = []\n",
    "    drop = []\n",
    "    squeeze = []\n",
    "    handle = []\n",
    "    \n",
    "    \n",
    "    print('Window Size= ' + str(window_size))\n",
    "    for n in np.arange(1,72):\n",
    "        indices = indices_dict[n]\n",
    "        data = dataset[n]\n",
    "        for l in indices[0]: #cropping for nothing data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[1]: #cropping for drop data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[2]: #cropping for squeeze data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    for sample in newNothing:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newHandle:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                handle.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newDrop:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newSqueeze:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    final_data = nothing+drop+squeeze+handle\n",
    "    \n",
    "    #create labels \n",
    "    #nothing = 1\n",
    "    #drop = 2\n",
    "    #squeeze = 3\n",
    "    nothing_labels = [1] * len(nothing)\n",
    "    print('Number of nothing data: ' + str(len(nothing_labels)))\n",
    "    drop_labels = [2] * len(drop)\n",
    "    print('Number of drop data: ' + str(len(drop_labels)))\n",
    "    squeeze_labels = [3] * len(squeeze)\n",
    "    print('Number of squeeze data: ' + str(len(squeeze_labels)))\n",
    "    \n",
    "    handle_labels = [4] * len(handle)\n",
    "    print('Number of Handle data: ' + str(len(handle_labels)))\n",
    "    \n",
    "    \n",
    "    labels = nothing_labels + drop_labels + squeeze_labels + handle_labels\n",
    "    \n",
    "    print(np.shape(labels))\n",
    "    return final_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_norollhandle(window_size):\n",
    "    nothing = []\n",
    "    drop = []\n",
    "    squeeze = []\n",
    "    handle = []\n",
    "    \n",
    "    \n",
    "    print('Window Size= ' + str(window_size))\n",
    "    for n in np.arange(1,72):\n",
    "        indices = indices_dict[n]\n",
    "        data = dataset[n]\n",
    "        for l in indices[0]: #cropping for nothing data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[1]: #cropping for drop data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "        for l in indices[2]: #cropping for squeeze data\n",
    "            start = l[0]\n",
    "            stop = l[1]\n",
    "            cropped = data[start:stop, :]\n",
    "            start1 = random.randint(0, len(cropped)%window_size)\n",
    "            stop1 = window_size+start1\n",
    "            while stop1 <= len(cropped):\n",
    "                crop = cropped[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    for sample in newNothing:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                nothing.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newDrop:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                drop.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "    for sample in newSqueeze:\n",
    "        start1 = random.randint(0, len(sample)%window_size)\n",
    "        stop1 = window_size+start1\n",
    "        while stop1 <= len(sample):\n",
    "                crop = sample[start1:stop1, :]\n",
    "                squeeze.append(crop)\n",
    "                start1+=window_size\n",
    "                stop1+=window_size\n",
    "                \n",
    "                \n",
    "    final_data = nothing+drop+squeeze\n",
    "    \n",
    "    #create labels \n",
    "    #nothing = 1\n",
    "    #drop = 2\n",
    "    #squeeze = 3\n",
    "    nothing_labels = [1] * len(nothing)\n",
    "    print('Number of nothing data: ' + str(len(nothing_labels)))\n",
    "    drop_labels = [2] * len(drop)\n",
    "    print('Number of drop data: ' + str(len(drop_labels)))\n",
    "    squeeze_labels = [3] * len(squeeze)\n",
    "    print('Number of squeeze data: ' + str(len(squeeze_labels)))\n",
    "\n",
    "    \n",
    "    labels = nothing_labels + drop_labels + squeeze_labels\n",
    "    \n",
    "    print(np.shape(labels))\n",
    "    return final_data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size= 10\n",
      "Number of nothing data: 23901\n",
      "Number of drop data: 15958\n",
      "Number of squeeze data: 28285\n",
      "Number of Handle data: 3366\n",
      "(71510,)\n",
      "Window Size= 20\n",
      "Number of nothing data: 11924\n",
      "Number of drop data: 7976\n",
      "Number of squeeze data: 14117\n",
      "Number of Handle data: 1669\n",
      "(35686,)\n",
      "Window Size= 30\n",
      "Number of nothing data: 7924\n",
      "Number of drop data: 5310\n",
      "Number of squeeze data: 9385\n",
      "Number of Handle data: 1106\n",
      "(23725,)\n",
      "Window Size= 40\n",
      "Number of nothing data: 5929\n",
      "Number of drop data: 3984\n",
      "Number of squeeze data: 7037\n",
      "Number of Handle data: 822\n",
      "(17772,)\n",
      "Window Size= 50\n",
      "Number of nothing data: 4746\n",
      "Number of drop data: 3182\n",
      "Number of squeeze data: 5608\n",
      "Number of Handle data: 654\n",
      "(14190,)\n",
      "Window Size= 60\n",
      "Number of nothing data: 3930\n",
      "Number of drop data: 2643\n",
      "Number of squeeze data: 4648\n",
      "Number of Handle data: 539\n",
      "(11760,)\n",
      "Window Size= 70\n",
      "Number of nothing data: 3368\n",
      "Number of drop data: 2273\n",
      "Number of squeeze data: 4003\n",
      "Number of Handle data: 458\n",
      "(10102,)\n",
      "Window Size= 80\n",
      "Number of nothing data: 2930\n",
      "Number of drop data: 1979\n",
      "Number of squeeze data: 3478\n",
      "Number of Handle data: 395\n",
      "(8782,)\n",
      "Window Size= 90\n",
      "Number of nothing data: 2591\n",
      "Number of drop data: 1752\n",
      "Number of squeeze data: 3073\n",
      "Number of Handle data: 349\n",
      "(7765,)\n",
      "Window Size= 100\n",
      "Number of nothing data: 2348\n",
      "Number of drop data: 1588\n",
      "Number of squeeze data: 2779\n",
      "Number of Handle data: 317\n",
      "(7032,)\n"
     ]
    }
   ],
   "source": [
    "windows = np.arange(10, 110, 10)\n",
    "filepath = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\Python\\Data'\n",
    "\n",
    "for w in windows:\n",
    "    \n",
    "    final_data, labels = create_dataset_noroll(w)\n",
    "    final_data = np.delete(final_data, [0,13,14,15], 2)\n",
    "    \n",
    "    nsamples, nx, ny = np.shape(final_data)\n",
    "    reformatted_data = np.reshape(final_data,(nsamples, nx*ny))\n",
    "    \n",
    "    np.savetxt(os.path.join(filepath,'final_data_X_raw_w' + str(w) + '.csv'), reformatted_data, delimiter=',')\n",
    "    np.savetxt(os.path.join(filepath,'final_data_Y_raw_w' + str(w) + '.csv'), labels, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature function block \n",
    "def impulse(data_matrix):\n",
    "    #total impulse function for a single matrix of data \n",
    "    #iterates over data and computes the total impulse for all sensors over time \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    impulse = 0\n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        time = data_matrix[:,0]\n",
    "        for i in np.arange(0,len(time)-1):\n",
    "            delta_t = time[i+1]- time[i]\n",
    "            averagef = (single_FSR[i+1] + single_FSR[i])/2 \n",
    "            impulse = impulse + averagef*delta_t\n",
    "    return impulse \n",
    "\n",
    "def jerk(data_matrix): \n",
    "    #iterates over data and computes the max jerk for each sensor over time\n",
    "    #takes the max jerk over all FSR sensors and returns  \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    jerk_array = []\n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        time = data_matrix[:,0]\n",
    "        all_jerks = []\n",
    "        for i in np.arange(0,len(time)-1):\n",
    "            delta_t = time[i+1] - time[i]\n",
    "            delta_f = single_FSR[i+1] - single_FSR[i]\n",
    "            all_jerks.append(delta_f/delta_t)\n",
    "        jerk_array.append(np.amax(all_jerks))\n",
    "    max_jerk = np.amax(jerk_array)\n",
    "    return max_jerk\n",
    "\n",
    "def max_force(data_matrix):\n",
    "    #max force readings across all sensors for a single matrix of data \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    force_array = [] \n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        max_force_sensor = np.amax(single_FSR)\n",
    "        force_array.append(max_force_sensor)\n",
    "    max_force = np.amax(force_array)\n",
    "    return max_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size= 100\n",
      "Number of nothing data: 2348\n",
      "Number of drop data: 1588\n",
      "Number of squeeze data: 2779\n",
      "Number of Handle data: 317\n",
      "(7032,)\n"
     ]
    }
   ],
   "source": [
    "final_data, labels = create_dataset_noroll(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per FSR feature function block \n",
    "\n",
    "def impulse(data_matrix):\n",
    "    #total impulse function for a single matrix of data \n",
    "    #iterates over data and computes the total impulse for all sensors over time \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    impulse_array = []\n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        time = data_matrix[:,0]\n",
    "        impulse = 0\n",
    "        for i in np.arange(0,len(time)-1):\n",
    "            delta_t = time[i+1]- time[i]\n",
    "            averagef = (single_FSR[i+1] + single_FSR[i])/2 \n",
    "            impulse = impulse + averagef*delta_t\n",
    "        impulse_array.append(impulse)\n",
    "    return impulse_array\n",
    "\n",
    "def jerk(data_matrix): \n",
    "    #iterates over data and computes the max jerk for each sensor over time\n",
    "    #takes the max jerk over all FSR sensors and returns  \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    jerk_array = []\n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        time = data_matrix[:,0]\n",
    "        all_jerks = []\n",
    "        for i in np.arange(0,len(time)-1):\n",
    "            delta_t = time[i+1] - time[i]\n",
    "            delta_f = single_FSR[i+1] - single_FSR[i]\n",
    "            all_jerks.append(delta_f/delta_t)\n",
    "        jerk_array.append(np.amax(all_jerks))\n",
    "    return jerk_array\n",
    "\n",
    "def max_force(data_matrix):\n",
    "    #max force readings across all sensors for a single matrix of data \n",
    "    fsr_data = data_matrix[:,1:13]\n",
    "    force_array = [] \n",
    "    for col in np.arange(1,13):\n",
    "        single_FSR = data_matrix[:,col]\n",
    "        max_force_sensor = np.amax(single_FSR)\n",
    "        force_array.append(max_force_sensor)\n",
    "    return force_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(max_force(final_data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size= 10\n",
      "Number of nothing data: 23901\n",
      "Number of drop data: 15958\n",
      "Number of squeeze data: 28285\n",
      "Number of Handle data: 3366\n",
      "(71510,)\n",
      "(71510, 36)\n",
      "Window Size= 20\n",
      "Number of nothing data: 11924\n",
      "Number of drop data: 7976\n",
      "Number of squeeze data: 14117\n",
      "Number of Handle data: 1669\n",
      "(35686,)\n",
      "(35686, 36)\n",
      "Window Size= 30\n",
      "Number of nothing data: 7924\n",
      "Number of drop data: 5310\n",
      "Number of squeeze data: 9385\n",
      "Number of Handle data: 1106\n",
      "(23725,)\n",
      "(23725, 36)\n",
      "Window Size= 40\n",
      "Number of nothing data: 5929\n",
      "Number of drop data: 3984\n",
      "Number of squeeze data: 7037\n",
      "Number of Handle data: 822\n",
      "(17772,)\n",
      "(17772, 36)\n",
      "Window Size= 50\n",
      "Number of nothing data: 4746\n",
      "Number of drop data: 3182\n",
      "Number of squeeze data: 5608\n",
      "Number of Handle data: 654\n",
      "(14190,)\n",
      "(14190, 36)\n",
      "Window Size= 60\n",
      "Number of nothing data: 3930\n",
      "Number of drop data: 2643\n",
      "Number of squeeze data: 4648\n",
      "Number of Handle data: 539\n",
      "(11760,)\n",
      "(11760, 36)\n",
      "Window Size= 70\n",
      "Number of nothing data: 3368\n",
      "Number of drop data: 2273\n",
      "Number of squeeze data: 4003\n",
      "Number of Handle data: 458\n",
      "(10102,)\n",
      "(10102, 36)\n",
      "Window Size= 80\n",
      "Number of nothing data: 2930\n",
      "Number of drop data: 1979\n",
      "Number of squeeze data: 3478\n",
      "Number of Handle data: 395\n",
      "(8782,)\n",
      "(8782, 36)\n",
      "Window Size= 90\n",
      "Number of nothing data: 2591\n",
      "Number of drop data: 1752\n",
      "Number of squeeze data: 3073\n",
      "Number of Handle data: 349\n",
      "(7765,)\n",
      "(7765, 36)\n",
      "Window Size= 100\n",
      "Number of nothing data: 2348\n",
      "Number of drop data: 1588\n",
      "Number of squeeze data: 2779\n",
      "Number of Handle data: 317\n",
      "(7032,)\n",
      "(7032, 36)\n"
     ]
    }
   ],
   "source": [
    "windows = np.arange(10, 110, 10)\n",
    "filepath = r'C:\\Users\\Andrew\\Documents\\GitHub\\Tensegrity-HRI\\Python\\Data'\n",
    "\n",
    "for w in windows:\n",
    "    \n",
    "    final_data, labels = create_dataset_noroll(w)\n",
    "    final_data_features = []\n",
    "    for d in final_data: \n",
    "        final_data_features.append(np.array([impulse(d), jerk(d), max_force(d)]).flatten())\n",
    "    print(np.shape(final_data_features))\n",
    "    \n",
    "    np.savetxt(os.path.join(filepath,'final_data_X_feat_w' + str(w) + '.csv'), final_data_features, delimiter=',')\n",
    "    np.savetxt(os.path.join(filepath,'final_data_Y_feat_w' + str(w) + '.csv'), labels, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
