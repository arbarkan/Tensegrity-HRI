{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from matplotlib.pyplot import clf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# improve progress bar display\n",
    "import tqdm\n",
    "import tqdm.auto\n",
    "tqdm.tqdm = tqdm.auto.tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and organize data\n",
    "\n",
    "filepath = \"/Users/salatiemann/Downloads/Data copy/test\"\n",
    "test_numbers = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20',\n",
    "      '21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40',\n",
    "      '41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','60',\n",
    "      '61','62','63','64','65','66','67','68','69','70','71','72']\n",
    "data = []\n",
    "for num in test_numbers:\n",
    "    filename = filepath + num + '.csv'\n",
    "    d = pd.read_csv(filename, names = [\"IND\", \"time\", \"FSR_1\", \"FSR_2\", \"FSR_3\", \"FSR_4\", \"FSR_5\", \"FSR_6\", \"FSR_7\", \n",
    "                                   \"FSR_8\", \"FSR_9\", \"FSR_10\", \"FSR_11\", \"FSR_12\",\"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "    d = d.drop(columns = [\"IND\"])\n",
    "    d = d.to_numpy()\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 7001, 16)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,0,0,3,1,1,1,1,1,1,3,0,1,1,1,1,1,1,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,1,1,1,1,0,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "         1,2,3,3,3,3,3,2,2,2,0,0,1,1,2,2,3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(labels)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 7001, 16)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin feature engineering\n",
    "\n",
    "def three_quarters(column):\n",
    "    max = np.max(column)\n",
    "    three_fourths = .75*max\n",
    "    e = []\n",
    "    j=0\n",
    "    for i in range(len(column)):\n",
    "        if column[i] <= .75*np.max(column):\n",
    "            j+=1\n",
    "    return j/len(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-309-6a84a1d5d5ec>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-309-6a84a1d5d5ec>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for j in range(len(array)):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# This function takes all 72 data points of size (7001,16) and puts them into a feature-engineered array.\n",
    "# Desired shape: 72 data points of size (6,16) --> (72,6,16)\n",
    "\n",
    "def condense(array):\n",
    "    condensed_data = np.zeros((len(array),6,len(array[0][0,:]))\n",
    "    for j in range(len(array)):\n",
    "        data_point = array[j]\n",
    "        number_of_columns = len(data_point[0,:])\n",
    "        D = np.zeros((6,number_of_columns),dtype=np.float64)\n",
    "        for i in range(number_of_columns):\n",
    "            column = data_point[:,i]\n",
    "            D[0,i] = np.mean(column)\n",
    "            D[1,i] = np.max(column)\n",
    "            D[2,i] = np.min(column)\n",
    "            D[3,i] = np.var(column)\n",
    "            D[4,i] = np.std(column)\n",
    "            D[5,i] = three_quarters(column)\n",
    "        #D=D.to_numpy()\n",
    "        condensed_data[j]=D\n",
    "        print('appended column {}'.format(j))\n",
    "        #print(D)\n",
    "        #print(condensed_data)\n",
    "    return condensed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point=data[0]\n",
    "column = data_point[:,0]\n",
    "len(column)\n",
    "D=[]\n",
    "e=np.ones((6,16))\n",
    "D.append(e)\n",
    "D.append(e)\n",
    "D\n",
    "D=np.asarray(D)\n",
    "b=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended column 0\n",
      "appended column 1\n",
      "appended column 2\n",
      "appended column 3\n",
      "appended column 4\n",
      "appended column 5\n",
      "appended column 6\n",
      "appended column 7\n",
      "appended column 8\n",
      "appended column 9\n",
      "appended column 10\n",
      "appended column 11\n",
      "appended column 12\n",
      "appended column 13\n",
      "appended column 14\n",
      "appended column 15\n",
      "appended column 16\n",
      "appended column 17\n",
      "appended column 18\n",
      "appended column 19\n",
      "appended column 20\n",
      "appended column 21\n",
      "appended column 22\n",
      "appended column 23\n",
      "appended column 24\n",
      "appended column 25\n",
      "appended column 26\n",
      "appended column 27\n",
      "appended column 28\n",
      "appended column 29\n",
      "appended column 30\n",
      "appended column 31\n",
      "appended column 32\n",
      "appended column 33\n",
      "appended column 34\n",
      "appended column 35\n",
      "appended column 36\n",
      "appended column 37\n",
      "appended column 38\n",
      "appended column 39\n",
      "appended column 40\n",
      "appended column 41\n",
      "appended column 42\n",
      "appended column 43\n",
      "appended column 44\n",
      "appended column 45\n",
      "appended column 46\n",
      "appended column 47\n",
      "appended column 48\n",
      "appended column 49\n",
      "appended column 50\n",
      "appended column 51\n",
      "appended column 52\n",
      "appended column 53\n",
      "appended column 54\n",
      "appended column 55\n",
      "appended column 56\n",
      "appended column 57\n",
      "appended column 58\n",
      "appended column 59\n",
      "appended column 60\n",
      "appended column 61\n",
      "appended column 62\n",
      "appended column 63\n",
      "appended column 64\n",
      "appended column 65\n",
      "appended column 66\n",
      "appended column 67\n",
      "appended column 68\n",
      "appended column 69\n",
      "appended column 70\n",
      "appended column 71\n",
      "appended column 72\n",
      "appended column 73\n",
      "appended column 74\n",
      "appended column 75\n",
      "appended column 76\n",
      "appended column 77\n",
      "appended column 78\n",
      "appended column 79\n",
      "appended column 80\n",
      "appended column 81\n",
      "appended column 82\n",
      "appended column 83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-20cdaf2ec950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatured_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatured_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatured_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-260-407a8a546499>\u001b[0m in \u001b[0;36mcondense\u001b[0;34m(array)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2744\u001b[0m     \"\"\"\n\u001b[1;32m   2745\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0;32m-> 2746\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "featured_data = condense(data)\n",
    "featured_data\n",
    "np.shape(featured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(featured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = np.shape(data)\n",
    "reformated_data = np.reshape(data,(nsamples, nx*ny))\n",
    "\n",
    "train = reformated_data[0:64]\n",
    "test = reformated_data[64:72]\n",
    "train_labels = labels[0:64]\n",
    "test_labels = labels[64:72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, X_test, y_train, y_test] = [train, test, train_labels, test_labels]\n",
    "model = GaussianNB().fit(train, train_labels)\n",
    "#model = GaussianNB().fit(reformated_data, labels)\n",
    "# print(clf.score(X_train, y_train))\n",
    "# print(clf.score(X_test, y_test))\n",
    "print(\"Predicted labels = \" + str(model.predict(test)))\n",
    "print(\"Correct labels =   \" + str(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "a = model.predict(test)\n",
    "for i in range(len(a)):\n",
    "    if a[i] == test_labels[i]:\n",
    "        total += 1\n",
    "percent_correct = total/len(a)\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(X_test)\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape([train, test, train_labels, test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(reformated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reformated_data[0:62]\n",
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = labels[0:62]\n",
    "test_labels = labels[62:72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = (train, train_labels)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((features, labels)).repeat().batch(12)\n",
    "\n",
    "features, labels = (test, test_labels)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((features, labels)).repeat().batch(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = train_dataset.__iter__()\n",
    "test_iter = test_dataset.__iter__()\n",
    "\n",
    "train_x, train_y = train_iter.get_next()\n",
    "test_x, test_y = test_iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "    #Pack the features into a single array.\n",
    "    features = tf.stack(list(features, axis=1))\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a simple model\n",
    "# net = tf.keras.layers.Dense(train_x, 8) # pass the first value from iter.get_next() as input\n",
    "# net = tf.keras.layers.dense(net, 8)\n",
    "# prediction = tf.layers.dense(net, 1)\n",
    "# loss = tf.losses.mean_squared_error(prediction, train_y) # pass the second value from iter.get_net() as label\n",
    "# train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l0 = tf.keras.layers.Dense(units=1, input_shape=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(units = 112016, input_shape=(None, 7001, 16)),\n",
    "    #tf.keras.layers.Dense(units=112016, input_shape=(None, 7001, 16), activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "# train = train.repeat().shuffle(62).batch(BATCH_SIZE)\n",
    "# test = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, epochs=1, steps_per_epoch=math.ceil(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
